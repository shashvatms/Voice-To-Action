# -*- coding: utf-8 -*-
"""Untitled43.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PvszaDUZ3oK3d9H7FBXNsvMwO4rGgnY6
"""

pip install torch transformers spacy whisper

!pip install spacy

!python -m spacy download en_core_web_sm

!pip install openai-whisper
!sudo apt update && sudo apt install ffmpeg
import whisper
import spacy
from transformers import pipeline

# Load pre-trained models
nlp = spacy.load("en_core_web_sm")  # spaCy for NER
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")  # BART for summarization
action_item_model = pipeline("text-classification", model="bert-base-uncased")  # BERT for action item detection (fine-tuned)

# Load Whisper model for speech-to-text
whisper_model = whisper.load_model("base")

# Function to transcribe audio to text
def transcribe_audio(audio_path):
    """
    Transcribe audio file to text using Whisper.
    """
    result = whisper_model.transcribe(audio_path)
    return result["text"]

# Function to extract meeting details using spaCy NER
def extract_meeting_details(text):
    """
    Extract date, time, and location from transcribed text using spaCy NER.
    """
    doc = nlp(text)
    meeting_details = {"date": None, "time": None, "location": None}

    for ent in doc.ents:
        if ent.label_ == "DATE":
            meeting_details["date"] = ent.text
        elif ent.label_ == "TIME":
            meeting_details["time"] = ent.text
        elif ent.label_ == "GPE" or ent.label_ == "LOC":  # Location entities
            meeting_details["location"] = ent.text

    return meeting_details

# Function to detect action items using BERT
def detect_action_items(text):
    """
    Detect action items from transcribed text using a fine-tuned BERT model.
    """
    # Example: Fine-tuned BERT model for action item detection
    action_items = action_item_model(text)
    return action_items

# Function to extract key points using BART summarization
def extract_key_points(text):
    """
    Extract key discussion points using BART summarization.
    """
    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
    return summary[0]["summary_text"]

# Function to generate structured actions
def generate_actions(meeting_details, action_items, key_points):
    """
    Generate structured actions (calendar events, to-do items, meeting notes).
    """
    calendar_event = {
        "date": meeting_details["date"],
        "time": meeting_details["time"],
        "location": meeting_details["location"]
    }

    to_do_items = [{"task": item["label"], "deadline": meeting_details["date"]} for item in action_items]

    meeting_notes = {
        "key_points": key_points,
        "action_items": to_do_items
    }

    return {
        "calendar_event": calendar_event,
        "to_do_items": to_do_items,
        "meeting_notes": meeting_notes
    }

# Main function to process audio and generate actions
def process_audio(audio_path):
    """
    Process audio file and generate structured actions.
    """
    # Step 1: Transcribe audio to text
    transcribed_text = transcribe_audio(audio_path)
    print("Transcribed Text:", transcribed_text)

    # Step 2: Extract meeting details
    meeting_details = extract_meeting_details(transcribed_text)
    print("Meeting Details:", meeting_details)

    # Step 3: Detect action items
    action_items = detect_action_items(transcribed_text)
    print("Action Items:", action_items)

    # Step 4: Extract key points
    key_points = extract_key_points(transcribed_text)
    print("Key Points:", key_points)

    # Step 5: Generate structured actions
    structured_actions = generate_actions(meeting_details, action_items, key_points)
    print("Structured Actions:", structured_actions)

    return structured_actions

# Example usage
if __name__ == "__main__":
    audio_path = "/content/WhatsApp Audio 2025-02-20 at 23.59.11_68850da4.mp3"  # Replace with your audio file path
    actions = process_audio(audio_path)

